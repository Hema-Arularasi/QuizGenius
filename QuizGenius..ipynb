{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961ea989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de61ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5bf200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the meaning of 'focus'?\n",
      "Question 2: What is the meaning of 'algorithm'?\n",
      "Question 3: What is the meaning of 'languag'?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "def generate_quiz_questions(text, num_questions=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    questions = []\n",
    "\n",
    "    for _ in range(num_questions):\n",
    "        random_sentence = random.choice(sentences)\n",
    "        words = preprocess_text(random_sentence)\n",
    "        \n",
    "        if words:\n",
    "            stemmer = PorterStemmer()\n",
    "            random_word = stemmer.stem(random.choice(words))\n",
    "            question = f\"What is the meaning of '{random_word}'?\"\n",
    "            questions.append(question)\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Example usage\n",
    "educational_content = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language. It involves the development of algorithms and models to enable computers to understand, interpret, and generate human-like text.\n",
    "\"\"\"\n",
    "\n",
    "quiz_questions = generate_quiz_questions(educational_content, num_questions=3)\n",
    "for i, question in enumerate(quiz_questions, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ca47e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the meaning of 'interaction'?\n",
      "Question 2: What is the meaning of 'interaction'?\n",
      "Question 3: What is the meaning of 'is'?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "def get_nouns_and_verbs(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "    nouns_verbs = [word.lower() for word, tag in tagged_words if tag.startswith('N') or tag.startswith('V')]\n",
    "    return nouns_verbs\n",
    "\n",
    "def generate_quiz_questions(text, num_questions=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    questions = []\n",
    "\n",
    "    for _ in range(num_questions):\n",
    "        random_sentence = random.choice(sentences)\n",
    "        nouns_verbs = get_nouns_and_verbs(random_sentence)\n",
    "\n",
    "        if nouns_verbs:\n",
    "            random_word = random.choice(nouns_verbs)\n",
    "            question = f\"What is the meaning of '{random_word}'?\"\n",
    "            questions.append(question)\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Example usage\n",
    "educational_content = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language. It involves the development of algorithms and models to enable computers to understand, interpret, and generate human-like text.\n",
    "\"\"\"\n",
    "\n",
    "quiz_questions = generate_quiz_questions(educational_content, num_questions=3)\n",
    "for i, question in enumerate(quiz_questions, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4195a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
